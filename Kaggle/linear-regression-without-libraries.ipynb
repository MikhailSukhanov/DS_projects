{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nIn this work, I decided to write my own implementation of the linear regression algorithm and compare its performance with the algorithm implemented in the Scikit-learn library.\n## Importing the required libraries","metadata":{"papermill":{"duration":0.004899,"end_time":"2023-04-22T17:14:29.363969","exception":false,"start_time":"2023-04-22T17:14:29.359070","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom typing import List","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.01872,"end_time":"2023-04-22T17:14:29.386562","exception":false,"start_time":"2023-04-22T17:14:29.367842","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T19:47:37.434447Z","iopub.execute_input":"2023-05-15T19:47:37.435127Z","iopub.status.idle":"2023-05-15T19:47:37.468638Z","shell.execute_reply.started":"2023-05-15T19:47:37.435096Z","shell.execute_reply":"2023-05-15T19:47:37.467040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data loading\nThe data frame will not be divided into train and test parts, since I'm only interested in the relative accuracy of the algorithms.","metadata":{"papermill":{"duration":0.003305,"end_time":"2023-04-22T17:14:29.393595","exception":false,"start_time":"2023-04-22T17:14:29.390290","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/startup-logistic-regression/50_Startups.csv')\ndf1 = df.copy().drop('State', axis = 1)\ndf1.head()","metadata":{"papermill":{"duration":0.05295,"end_time":"2023-04-22T17:14:29.450106","exception":false,"start_time":"2023-04-22T17:14:29.397156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T19:47:37.470306Z","iopub.execute_input":"2023-05-15T19:47:37.470634Z","iopub.status.idle":"2023-05-15T19:47:37.516966Z","shell.execute_reply.started":"2023-05-15T19:47:37.470607Z","shell.execute_reply":"2023-05-15T19:47:37.515374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Algorithm implementation\nThe target variable is assumed to be the last column of the data frame.","metadata":{"papermill":{"duration":0.003529,"end_time":"2023-04-22T17:14:29.457592","exception":false,"start_time":"2023-04-22T17:14:29.454063","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Linear function\ndef linear_func(x: List[float], coeff: List[float]) -> float:\n    assert len(coeff) - len(x) == 1\n    return coeff[0] + sum([x_i * coeff_i for x_i, coeff_i in zip(x, coeff[1:])])\n\n#A function that calculates new coefficients based on gradient descent\ndef new_coeff(prev_coeff: List[float], gradient: List[float], step: float) -> List[float]:\n    assert len(prev_coeff) == len(gradient)\n    grad_step = [step * grad for grad in gradient]\n    return [coeff - grad for coeff, grad in zip(prev_coeff, grad_step)]\n\n#Function for calculating the average relative error\ndef avg_rel_error(y: List[float], y_pred: List[float]) -> float:\n    error = [abs(y_i - y_pred_i) / y_i for y_i, y_pred_i in zip(y, y_pred)]\n    return sum(error) / len(y)\n\n#Function to fit the data by linear regression. At the output, the function gives the coefficients of the linear model\ndef linear_regression(df: pd.DataFrame, step: int = 0.000001) -> List[float]:\n    rel_error0, rel_error1 = 2, 1\n    \n    #Assignment of random values to coefficients for subsequent optimization of the sum of squared errors function\n    coeff = [random.random() for _ in range(df.shape[1])]\n\n    #The learning process stops when the relative error does not decrease\n    while rel_error0 - rel_error1 > 0.00000001:\n        rel_error0 = rel_error1\n        gradient = []\n\n        #Calculating the gradient of the sum of squared errors function at the current point\n        for i in range(len(coeff)):\n            if i == 0:\n                gradient.append(sum([-2 * (df.iloc[j, -1] - linear_func(df.iloc[j, :-1], coeff)) for j in range(df.shape[0])]))\n            else:\n                gradient.append(sum([-2 * df.iloc[j, i - 1] * (df.iloc[j, -1] - linear_func(df.iloc[j, :-1], coeff)) for j in range(df.shape[0])]))\n\n        #Calculating the coordinates of a new point using gradient descent\n        coeff = new_coeff(coeff, gradient, step)\n        \n        #Calculation of the average relative error in order to decide whether to continue training or not\n        y_pred = [linear_func(df.iloc[k, :-1], coeff) for k in range(df.shape[0])]\n        rel_error1 = avg_rel_error(df.iloc[:, -1], y_pred)\n    \n    return coeff","metadata":{"papermill":{"duration":0.024453,"end_time":"2023-04-22T17:14:29.485943","exception":false,"start_time":"2023-04-22T17:14:29.461490","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T19:47:37.519821Z","iopub.execute_input":"2023-05-15T19:47:37.520191Z","iopub.status.idle":"2023-05-15T19:47:37.537277Z","shell.execute_reply.started":"2023-05-15T19:47:37.520156Z","shell.execute_reply":"2023-05-15T19:47:37.536198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance comparison\n## My algorithm implementation\nLearning step was chosen empirically.","metadata":{"papermill":{"duration":0.003446,"end_time":"2023-04-22T17:14:29.493280","exception":false,"start_time":"2023-04-22T17:14:29.489834","status":"completed"},"tags":[]}},{"cell_type":"code","source":"random.seed(1)\n\ncoeff = linear_regression(df1, 0.0000000000001)\npredict = [linear_func(df1.iloc[i, :-1], coeff) for i in range(df1.shape[0])]\n\nerror = avg_rel_error(df1.iloc[:, -1], predict)","metadata":{"papermill":{"duration":13.109361,"end_time":"2023-04-22T17:14:42.606319","exception":false,"start_time":"2023-04-22T17:14:29.496958","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T19:47:37.539969Z","iopub.execute_input":"2023-05-15T19:47:37.540355Z","iopub.status.idle":"2023-05-15T19:47:59.823552Z","shell.execute_reply.started":"2023-05-15T19:47:37.540307Z","shell.execute_reply":"2023-05-15T19:47:59.821946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scikit-learn's LinearRegression","metadata":{"papermill":{"duration":0.003598,"end_time":"2023-04-22T17:14:42.613975","exception":false,"start_time":"2023-04-22T17:14:42.610377","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\ndf2 = df.copy().drop('State', axis = 1)\n\nsk_model = LinearRegression(fit_intercept = False).fit(df2.iloc[:, :-1], df2.iloc[:, -1])\nsk_predict = sk_model.predict(df2.iloc[:, :-1])\n\nsk_error = avg_rel_error(df2.iloc[:, -1], sk_predict)","metadata":{"papermill":{"duration":1.257995,"end_time":"2023-04-22T17:14:43.875829","exception":false,"start_time":"2023-04-22T17:14:42.617834","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T19:47:59.824714Z","iopub.execute_input":"2023-05-15T19:47:59.825027Z","iopub.status.idle":"2023-05-15T19:48:00.448474Z","shell.execute_reply.started":"2023-05-15T19:47:59.824996Z","shell.execute_reply":"2023-05-15T19:48:00.447272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results","metadata":{"papermill":{"duration":0.003514,"end_time":"2023-04-22T17:14:43.883361","exception":false,"start_time":"2023-04-22T17:14:43.879847","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print('My algorithm\\'s error:', error)\nprint('Scikit-learn\\'s error:', sk_error)","metadata":{"papermill":{"duration":0.015518,"end_time":"2023-04-22T17:14:43.902995","exception":false,"start_time":"2023-04-22T17:14:43.887477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-05-15T19:48:00.450366Z","iopub.execute_input":"2023-05-15T19:48:00.451515Z","iopub.status.idle":"2023-05-15T19:48:00.458622Z","shell.execute_reply.started":"2023-05-15T19:48:00.451470Z","shell.execute_reply":"2023-05-15T19:48:00.456680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The values are almost equal. I think this is a good result.","metadata":{"papermill":{"duration":0.003554,"end_time":"2023-04-22T17:14:43.910591","exception":false,"start_time":"2023-04-22T17:14:43.907037","status":"completed"},"tags":[]}}]}